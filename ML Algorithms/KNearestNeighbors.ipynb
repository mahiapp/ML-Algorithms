{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf79a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from heapq import nsmallest\n",
    "import copy\n",
    "from scipy.stats import mode\n",
    "\n",
    "%run DataPreProcessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf9111",
   "metadata": {},
   "source": [
    "# Distance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b21231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideanDistance(query_point_vector,comparison_vector,):\n",
    "    '''\n",
    "    Calculate Euclidean distance between two points\n",
    "    \n",
    "    @param query_point_vector: test input data vector\n",
    "    @param comparison_vector: train vector to compare with\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Mathematically calculates the Euclidean distance between two vectors\n",
    "    euclidean_distance = np.sqrt(np.sum((query_point_vector-comparison_vector)**2))  \n",
    "    \n",
    "    return euclidean_distance\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15fb59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBF(distances,bandwidth):\n",
    "    '''\n",
    "    \n",
    "    Applies a Radial Basis Function Kernel to make the predictions for regression sets\n",
    "    \n",
    "    @param distances: list of k nearest distances from the KNN function\n",
    "    @param bandwidth: bandwidth value(1/sigma) for the kernel function\n",
    "    \n",
    "    '''       \n",
    "    #Calculate Gaussian(RBF) kernel\n",
    "    #print(-bandwidth*(distances**2))\n",
    "    #print(np.exp(-bandwidth*(distances**2)))\n",
    "    #print((np.exp(-bandwidth*(distances**2))).mean())\n",
    "    kernel_value = (np.exp(-bandwidth*(distances**2))).mean()\n",
    "    \n",
    "    return kernel_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54d7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValueDifferenceMetric(dataset,class_label):\n",
    "    '''\n",
    "    \n",
    "    Calculates the value difference metric for categorical data, \n",
    "    and returns a dictionary of the value differences between each \n",
    "    nominal feature value of each class\n",
    "    \n",
    "    @param dataset: The complete dataset\n",
    "    @param class_label: The label of the class column in the dataset\n",
    "    \n",
    "    '''   \n",
    "    #Initializes the final vdm dict to be returned\n",
    "    vdm_tables = {}\n",
    "    \n",
    "    #Gets all the unique class and all feature names\n",
    "    classes = dataset[class_label].unique()\n",
    "    features = list((dataset.drop(columns=class_label)).columns)\n",
    "    \n",
    "    #Iterates through each of the features    \n",
    "    for feature in features:\n",
    "        #Gets all the individual categorical values of each feature\n",
    "        feature_vals = dataset[feature].unique()\n",
    "        feature_distances = {}\n",
    "        \n",
    "        #Gets all possible combinations of the feature values\n",
    "        feature_combos = itertools.combinations(feature_vals,2)\n",
    "        \n",
    "        #Calculates the VDM value for each combo of each class and \n",
    "        #adds it to total VDM for that combo\n",
    "        for combo in feature_combos:\n",
    "            vdm = 0\n",
    "            total_feature_1 = dataset[feature].value_counts()[combo[0]]\n",
    "            total_feature_2 = dataset[feature].value_counts()[combo[1]]\n",
    "            for class_val in classes:\n",
    "                inst_vdm = 0\n",
    "                \n",
    "                feature_1_curr_class_count = len(dataset[(dataset[feature]==combo[0]) & (dataset[class_label]==class_val)])\n",
    "                feature_2_curr_class_count = len(dataset[(dataset[feature]==combo[1]) & (dataset[class_label]==class_val)])\n",
    "                \n",
    "                inst_vdm = np.abs((feature_1_curr_class_count/total_feature_1)-(feature_2_curr_class_count/total_feature_2))\n",
    "                \n",
    "                vdm = vdm + inst_vdm\n",
    "            feature_distances[combo]=vdm\n",
    "        #Adds the dictionary of all the combos of one feature to the complete\n",
    "        #VDM dict for all the features\n",
    "        vdm_tables[feature]=feature_distances  \n",
    "        \n",
    "    return [vdm_tables,features]          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beb70b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CategoricalDistances(query_point_vector,comparison_vector,features,vdm_table):\n",
    "    '''\n",
    "    Calculate distance between two categorical vectors using the Value Difference Metric\n",
    "    \n",
    "    @param query_point_vector: test input data vector\n",
    "    @param comparison_vector: train vector to compare with\n",
    "    @param features: categorical feature names\n",
    "    @param vdm_tables: dictionary of all the feature value combos \n",
    "    and their corresponding VDM(result of the previous Value Difference Metric function)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #Creates a dataframe with the feature names as the headers\n",
    "    #the two input vectors as rows of the dataframe\n",
    "    temp_df = pd.DataFrame(columns=features)    \n",
    "    temp_df.loc[len(temp_df)] = query_point_vector\n",
    "    temp_df.loc[len(temp_df)] = comparison_vector\n",
    "    \n",
    "    #Initializes the distance to 0\n",
    "    dist = 0\n",
    "   \n",
    "    #Iterates through each feature \n",
    "    for (feature,data) in temp_df.iteritems():\n",
    "        if feature in vdm_table:\n",
    "            #Gets the feature VDM dictionary from the overall VDM dict input\n",
    "            feature_vdm = vdm_table.get(feature)\n",
    "            \n",
    "            #Gets the VDM distance value between the \n",
    "            #query and comparison vector values for the specific feature\n",
    "            if data[0] != data[1]:\n",
    "                if (str(data[1]),str(data[0])) in feature_vdm:\n",
    "                    combo = (str(data[1]),str(data[0]))\n",
    "                else:\n",
    "                    combo = (str(data[0]),str(data[1]))\n",
    "                \n",
    "                #All individual feature distances summed together for final distance\n",
    "                curr_dist = feature_vdm.get(combo)\n",
    "                dist = dist+float(curr_dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f808d",
   "metadata": {},
   "source": [
    "\n",
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb88937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThresholds(target):   \n",
    "    '''\n",
    "    Gets error threshold values for tuning\n",
    "    \n",
    "    @param target: target vector\n",
    "    \n",
    "    '''\n",
    "     #Gets the range of the target and gets the threholds for the 90%, 95%, and 99% confidence intervals\n",
    "    arr_range = np.max(target) - np.min(target)\n",
    "    accuracies = [0.9,0.95,0.99]\n",
    "    thresholds = []\n",
    "    \n",
    "    #Adds each threshold value to list and returns\n",
    "    for value in accuracies:\n",
    "        thresholds.append((1-value)*arr_range)\n",
    "    return thresholds\n",
    "            \n",
    "def getAllTuneVals(dataset,task_type,class_label,categorical=False):\n",
    "    '''\n",
    "    Tunes the numer of neighbors, error, and bandwidth\n",
    "    \n",
    "    @param dataset: the 20% of dataset for tuning\n",
    "    @param class_label: class label\n",
    "    @param nominal_features: list of nominal features, if any\n",
    "    '''\n",
    "    \n",
    "    k_list = list(range(1,11))\n",
    "    \n",
    "    if task_type=='Classification':\n",
    "        errors_dict = {}\n",
    "        for num in k_list:\n",
    "            class_error = RunExperiment(dataset, task_type, k = 5, class_label = class_label, tuning=True, knn=num, error=None, bandwidth=None, categorical=categorical)\n",
    "            errors_dict[num]=class_error\n",
    "        return min(errors_dict, key=errors_dict.get)\n",
    "    if task_type == 'Regression':\n",
    "        sigmas = [.1,1,10,100]\n",
    "        bandwidths = [1/sigma for sigma in sigmas]\n",
    "        thresholds = getThresholds(dataset[class_label].to_numpy()) \n",
    "        \n",
    "        params_list = [k_list,bandwidths,thresholds]\n",
    "        param_combinations = [p for p in itertools.product(*params_list)]\n",
    "        errors_dict = {}\n",
    "        \n",
    "        for combo in param_combinations:\n",
    "            mse = RunExperiment(dataset, task_type, k = 5, knn_type='knn',class_label = class_label, tuning=True, knn = combo[0], error=combo[1], bandwidth=combo[2],categorical=categorical)\n",
    "            errors_dict[tuple(combo)]=mse\n",
    "        return list(min(errors_dict, key=errors_dict.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d3b73",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72955a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate KNN\n",
    "def KNN(train, test, k, class_label,task_type,bandwidth=None,categorical=False,vdm_dict=None,nominal_features=None):\n",
    "    '''\n",
    "    Runs the K nearest neighbors algorithms and returns the predictions\n",
    "    \n",
    "    @param train: training data\n",
    "    @param test: testing data\n",
    "    @param k: number of nearest neighbors\n",
    "    @param class_label: class label\n",
    "    @param task_type: indicates classification or regression\n",
    "    @param bandwidth: tuned bandwidth for the RBF kernel\n",
    "    @param categorical: boolean value indicating if data is categorical\n",
    "    @param vdm_dict: value difference metric mapping table (only needed if categorical is True)\n",
    "    @param nominal_features: list of nominal features (only needed if categorical is True)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    train_data = (train.drop(columns=[class_label])).to_numpy()\n",
    "    train_target=train[class_label].to_numpy()\n",
    "    test_data = (test.drop(columns=[class_label])).to_numpy()\n",
    "    \n",
    "    predicted_values = []\n",
    "    \n",
    "    if task_type == 'Classification':\n",
    "        #Loop through the Datapoints to be classified\n",
    "        for query_row in test_data: \n",
    "\n",
    "            #Array to store distances\n",
    "            distances = []\n",
    "\n",
    "            #Loop through each training Data\n",
    "            for j in range(len(train_data)):\n",
    "                if categorical == False:\n",
    "                    distance = EuclideanDistance(query_row, np.array(train_data[j,:])) \n",
    "                if categorical == True:\n",
    "                    distance = CategoricalDistances(query_row,np.array(train_data[j,:]),nominal_features, vdm_dict)\n",
    "                \n",
    "                #Calculating the distance\n",
    "                distances.append(distance) \n",
    "            distances = np.array(distances) \n",
    "            #Sorting the array while preserving the index\n",
    "            #Keeping the first K datapoints\n",
    "            k_nearest_distances = np.argsort(distances)[:k] \n",
    "   \n",
    "\n",
    "            #Labels of the K datapoints from above\n",
    "            k_nearest_classes = train_target[k_nearest_distances]\n",
    "    \n",
    "            \n",
    "            print('Query Row')\n",
    "            print(query_row)\n",
    "            print('K Nearest Distances')\n",
    "            print(k_nearest_distances)\n",
    "            \n",
    "            print('K Nearest Classes')\n",
    "            print(k_nearest_classes)\n",
    "            \n",
    "            \n",
    "            #Majority voting\n",
    "            #print(k_nearest_classes)\n",
    "            prediction = mode(k_nearest_classes).mode[0]\n",
    "            predicted_values.append(prediction)        \n",
    "            \n",
    "    if task_type == 'Regression':\n",
    "        #Loop through the Datapoints to be classified\n",
    "        for query_row in test_data: \n",
    "            #Array to store distances\n",
    "            distances = []\n",
    "\n",
    "            #Loop through each training Data\n",
    "            for j in range(len(train_data)): \n",
    "                distance = EuclideanDistance(query_row, np.array(train_data[j,:])) \n",
    "                #Calculating the distance\n",
    "                distances.append(distance) \n",
    "            distances = np.array(distances) \n",
    "            #Sorting the array while preserving the index\n",
    "            #Keeping the first K datapoints\n",
    "            k_nearest_distances = np.argsort(distances)[:k] \n",
    "            \n",
    "\n",
    "            #Majority voting\n",
    "            prediction = RBF(k_nearest_distances,bandwidth)\n",
    "            predicted_values.append(prediction)\n",
    "            \n",
    "            \n",
    "            print('Query Row')\n",
    "            print(query_row)\n",
    "            print('K Nearest Distances')\n",
    "            print(k_nearest_distances)\n",
    "            \n",
    "            print('Prediction')\n",
    "            print(prediction)\n",
    "           \n",
    "\n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb647a71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to calculate KNN\n",
    "def EditedKNN(train, test, k, class_label,task_type,bandwidth=None,error=None, categorical=False,vdm_dict=None,nominal_features=None,prev_accuracy=0):\n",
    "    '''\n",
    "    Runs the edited nearest neighbors algorithms and returns the edited training data\n",
    "    \n",
    "    @param train: training data\n",
    "    @param test: testing data\n",
    "    @param k: number of nearest neighbors\n",
    "    @param class_label: class label\n",
    "    @param task_type: indicates classification or regression\n",
    "    @param bandwidth: tuned bandwidth for the RBF kernel\n",
    "    @param categorical: boolean value indicating if data is categorical\n",
    "    @param vdm_dict: value difference metric mapping table (only needed if categorical is True)\n",
    "    @param nominal_features: list of nominal features (only needed if categorical is True)\n",
    "    \n",
    "    '''\n",
    "    train_data = (train.drop(columns=[class_label])).to_numpy()\n",
    "    train_target=train[class_label].to_numpy()\n",
    "    test_data = (test.drop(columns=[class_label])).to_numpy()\n",
    "    test_target = test[class_label].to_numpy()\n",
    "    predicted_values = []\n",
    "    remove_list = []\n",
    "    edit_knn=1\n",
    "    completed=False\n",
    "\n",
    "    if task_type == 'Classification':\n",
    "        #Loop through the Datapoints to be classified\n",
    "        for idx in range(0,len(test_data)): \n",
    "            #Array to store distances\n",
    "            distances = []\n",
    "\n",
    "            #Loop through each training Data\n",
    "            for j in range(len(train_data)):\n",
    "                if categorical == False:\n",
    "                    distance = EuclideanDistance(test_data[idx], np.array(train_data[j,:])) \n",
    "                if categorical == True:\n",
    "                    distance = CategoricalDistances(test_data[idx],np.array(train_data[j,:]),nominal_features, vdm_dict)\n",
    "                \n",
    "                #Calculating the distance\n",
    "                distances.append(distance) \n",
    "            distances = np.array(distances) \n",
    "            #Sorting the array while preserving the index\n",
    "            #Keeping the first K datapoints\n",
    "            k_nearest_distances = np.argsort(distances)[:edit_knn]\n",
    "            #Labels of the K datapoints from above\n",
    "            k_nearest_classes = train_target[k_nearest_distances]\n",
    "\n",
    "            #Majority voting\n",
    "            prediction = mode(k_nearest_classes).mode[0]\n",
    "            \n",
    "            #Adds the incorrect prediction index to the list of indices to remove\n",
    "            if prediction != test_target[idx]:\n",
    "                remove_list.append(k_nearest_distances[0])\n",
    "         \n",
    "        #Removes the specified indices and gets the accuracy of the edited trian data\n",
    "        edited_train = train.drop(train.index[remove_list])\n",
    "        \n",
    "        print('To Remove')\n",
    "        print(remove_list)\n",
    "        print(len(remove_list))\n",
    "        print('Before Editing')\n",
    "        print(len(train))\n",
    "        print('After Editing')\n",
    "        print(len(edited_train))\n",
    "        \n",
    "        new_predicted = KNN(edited_train, test, k, class_label,task_type,categorical=categorical,vdm_dict=vdm_dict, nominal_features=nominal_features)\n",
    "        new_accuracy = Evaluate(task_type,test_target,new_predicted)[0]\n",
    "\n",
    "        #If the accuracy is lower or the size of the edited train is unchanged, the training is complete\n",
    "        if new_accuracy<prev_accuracy or len(edited_train)==len(train):\n",
    "            completed==True\n",
    "        #If not the function is called recursively with the new edited train\n",
    "        else:\n",
    "            EditedKNN(edited_train, test, k, class_label,task_type,categorical=categorical,vdm_dict=vdm_dict, nominal_features=nominal_features,prev_accuracy=new_accuracy)\n",
    "        \n",
    "    \n",
    "        #returns the final edited train set\n",
    "        return edited_train\n",
    "            \n",
    "    if task_type == 'Regression':\n",
    "        #Loop through the Datapoints to be classified\n",
    "        for idx in range(0,len(test_data)): \n",
    "            #Array to store distances\n",
    "            distances = []\n",
    "\n",
    "            #Loop through each training Data\n",
    "            for j in range(len(train_data)): \n",
    "                distance = EuclideanDistance(test_data[idx], np.array(train_data[j,:])) \n",
    "                #Calculating the distance\n",
    "                distances.append(distance) \n",
    "            distances = np.array(distances) \n",
    "            #Sorting the array while preserving the index\n",
    "            #Keeping the first K datapoints\n",
    "            k_nearest_distances = np.argsort(distances)[:edit_knn] \n",
    "            \n",
    "\n",
    "            #Majority voting\n",
    "            prediction = RBF(k_nearest_distances,bandwidth)\n",
    "            if np.abs(prediction - test_target[idx])>error:\n",
    "                remove_list.append(k_nearest_distances[0])\n",
    "        \n",
    "    \n",
    "        edited_train = train.drop(train.index[remove_list])\n",
    "        \n",
    "  \n",
    "        \n",
    "        new_predicted = KNN(edited_train, test, k, class_label,task_type,bandwidth=bandwidth,categorical=categorical,vdm_dict=vdm_dict, nominal_features=nominal_features)\n",
    "        new_accuracy = Evaluate(task_type,test_target,new_predicted,error=error)[0]\n",
    "\n",
    "        if (new_accuracy<prev_accuracy) or (len(edited_train)==len(train)):\n",
    "            completed==True\n",
    "        else:\n",
    "            EditedKNN(edited_train, test, k, class_label,task_type,categorical=categorical,vdm_dict=vdm_dict, nominal_features=nominal_features, bandwidth=bandwidth, error=error,prev_accuracy=new_accuracy)\n",
    "        \n",
    "        return edited_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0888b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CondensedKNN(condensed_train, test, k, class_label,task_type,bandwidth=None,error=None, categorical=False,vdm_dict=None,nominal_features=None):\n",
    "    '''\n",
    "    Runs the condensed nearest neighbors algorithms and returns the edited training data\n",
    "    \n",
    "    @param train: training data\n",
    "    @param test: testing data\n",
    "    @param k: number of nearest neighbors\n",
    "    @param class_label: class label\n",
    "    @param task_type: indicates classification or regression\n",
    "    @param bandwidth: tuned bandwidth for the RBF kernel\n",
    "    @param categorical: boolean value indicating if data is categorical\n",
    "    @param vdm_dict: value difference metric mapping table (only needed if categorical is True)\n",
    "    @param nominal_features: list of nominal features (only needed if categorical is True)\n",
    "    \n",
    "    '''\n",
    "    train_data = (condensed_train.drop(columns=[class_label])).to_numpy()\n",
    "    train_target=condensed_train[class_label].to_numpy()\n",
    "    test_data = (test.drop(columns=[class_label])).to_numpy()\n",
    "    test_target = test[class_label].to_numpy()\n",
    "    \n",
    "    add_to_condensed_list = []\n",
    "    condense_knn=1\n",
    "    \n",
    "    completed=False\n",
    "\n",
    "    if task_type == 'Classification':\n",
    "        #Loop through the Datapoints to be classified\n",
    "        for idx in range(0,len(test_data)): \n",
    " \n",
    "            #Array to store distances\n",
    "            distances = []\n",
    "\n",
    "            #Loop through each training Data\n",
    "            for j in range(0,len(train_data)):\n",
    "                if categorical == False:\n",
    "                    distance = EuclideanDistance(test_data[idx], np.array(train_data[j,:])) \n",
    "                if categorical == True:\n",
    "                    distance = CategoricalDistances(test_data[idx],np.array(train_data[j,:]),nominal_features, vdm_dict)\n",
    "\n",
    "                #Calculating the distance\n",
    "                distances.append(distance)\n",
    "\n",
    "            distances = np.array(distances)\n",
    "            #Sorting the array while preserving the index\n",
    "            #Keeping the first K datapoints\n",
    "            k_nearest_distances = np.argsort(distances)[:condense_knn]\n",
    "            #Labels of the K datapoints from above\n",
    "            k_nearest_classes = train_target[k_nearest_distances]\n",
    "\n",
    "            #Majority voting\n",
    "            prediction = mode(k_nearest_classes).mode[0]\n",
    "            \n",
    "            #Adds the incorrect prediction index to the list of indices to move to the condensed training list\n",
    "            if prediction != test_target[idx]:\n",
    "                add_to_condensed_list.append(idx)\n",
    "\n",
    "        print('To Move to Condensed')\n",
    "        print(add_to_condensed_list)\n",
    "        print(len(add_to_condensed_list))\n",
    "        print('Before Condensing')\n",
    "        print(len(condensed_train))\n",
    "        \n",
    "        #If there are no points to add to the condensed list, the list is complete \n",
    "        if len(add_to_condensed_list) == 0:\n",
    "            completed==True\n",
    "           \n",
    "        #Adds the specified indices to the condensed list and removes them from the original list\n",
    "        else:          \n",
    "            add_df = test.iloc[add_to_condensed_list] \n",
    "\n",
    "            condensed_train = condensed_train.append(add_df)\n",
    "            test = test.drop(test.index[add_to_condensed_list])\n",
    "            \n",
    "            print('After Condensing')\n",
    "            print(len(condensed_train))\n",
    "            #Runs recursively with new condensed training list\n",
    "            CondensedKNN(condensed_train, test, k, class_label,task_type,categorical=categorical,vdm_dict=vdm_dict, nominal_features=nominal_features)\n",
    "        \n",
    "        return condensed_train\n",
    "    \n",
    "    if task_type == 'Regression':\n",
    "        #Loop through the Datapoints to be classified\n",
    "        for idx in range(0,len(test_data)): \n",
    "            #print(idx)\n",
    "            #Array to store distances\n",
    "            distances = []\n",
    "\n",
    "            #Loop through each training Data\n",
    "            for j in range(0,len(train_data)):\n",
    "                if categorical == False:\n",
    "                    distance = EuclideanDistance(test_data[idx], np.array(train_data[j,:])) \n",
    "                if categorical == True:\n",
    "                    distance = CategoricalDistances(test_data[idx],np.array(train_data[j,:]),nominal_features, vdm_dict)\n",
    "\n",
    "                #Calculating the distance\n",
    "                distances.append(distance)\n",
    "\n",
    "            distances = np.array(distances)\n",
    "            #Sorting the array while preserving the index\n",
    "            #Keeping the first K datapoints\n",
    "            k_nearest_distances = np.argsort(distances)[:condense_knn]\n",
    "            #Labels of the K datapoints from above\n",
    "            k_nearest_classes = train_target[k_nearest_distances]\n",
    "\n",
    "            #Majority voting\n",
    "            prediction = RBF(k_nearest_distances,bandwidth)\n",
    "            if np.abs(prediction - test_target[idx])>error:\n",
    "                add_to_condensed_list.append(idx)\n",
    "\n",
    "        if len(add_to_condensed_list) == 0:\n",
    "            completed==True\n",
    "            \n",
    "        else:          \n",
    "            add_df = test.iloc[add_to_condensed_list] \n",
    "            \n",
    "            condensed_train = condensed_train.append(add_df)\n",
    "            test = test.drop(test.index[add_to_condensed_list])\n",
    "\n",
    "            CondensedKNN(condensed_train, test, k, class_label,task_type,categorical=categorical,vdm_dict=vdm_dict, nominal_features=nominal_features,error=error,bandwidth=bandwidth)\n",
    "        \n",
    "        #returns the final condensed train set\n",
    "        return condensed_train\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
