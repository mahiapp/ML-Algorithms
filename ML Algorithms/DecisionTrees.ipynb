{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf79a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from heapq import nsmallest\n",
    "import copy\n",
    "from scipy.stats import mode\n",
    "from random import choice\n",
    "\n",
    "%run DataPreProcessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd93ba",
   "metadata": {},
   "source": [
    "# Classification Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c964389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateFeatureEntropy(dataset):\n",
    "    '''\n",
    "    Calculates the total entropy of a dataset\n",
    "    \n",
    "    @param dataset: classification target set\n",
    "    '''\n",
    "    #Gets\n",
    "    values = dataset.unique()\n",
    "    entropy = 0\n",
    "    for value in values:\n",
    "        count = len(dataset[dataset == value])\n",
    "        p = count / len(dataset)\n",
    "        entropy += -p * math.log(p, 2)\n",
    "    return entropy\n",
    "\n",
    "def CalculateFeatureInformationGain(dataset, feature, target):\n",
    "    '''\n",
    "    Calculates information gain of a feature\n",
    "    \n",
    "    @param dataset: classification set \n",
    "    @param feature: the feature\n",
    "    @param target: class label\n",
    "    '''\n",
    "    # Calculate the entropy of the entire dataset\n",
    "    entropy_total = CalculateFeatureEntropy(dataset[target])\n",
    "\n",
    "    # Calculate the entropy of the feature\n",
    "    values = dataset[feature].unique()\n",
    "    entropy_feature = 0\n",
    "    for value in values:\n",
    "        subset = dataset[dataset[feature] == value]\n",
    "        weight = len(subset) / len(dataset)\n",
    "        entropy_feature += weight * CalculateFeatureEntropy(subset[target])\n",
    "\n",
    "    # Calculate the information gain\n",
    "    info_gain = entropy_total - entropy_feature\n",
    "    return [info_gain,values]\n",
    "\n",
    "def CalculateFeatureGainRatio(dataset,feature,target):\n",
    "    '''\n",
    "    Calculates the gain ratio of the feature\n",
    "    \n",
    "    @param dataset: classification set \n",
    "    @param feature: the feature\n",
    "    @param target: class label\n",
    "    '''\n",
    "        \n",
    "    #Calls functions to get the information gain of the feature as well as the unique \n",
    "    #values of the feature\n",
    "    feature_gain = CalculateFeatureInformationGain(dataset, feature, target)[0]\n",
    "    feature_values = CalculateFeatureInformationGain(dataset, feature, target)[1]\n",
    "    feature_size = len(dataset.index)\n",
    "    IV = 0\n",
    "    \n",
    "    #Calculates the intrinsic value over all the unique feature values\n",
    "    for value in feature_values:\n",
    "        value_count = dataset[feature].value_counts()[value]\n",
    "        IV = IV + ((-value_count/feature_size)*np.log2(value_count/feature_size))\n",
    "\n",
    "    if IV==0:\n",
    "        IV=0.0001\n",
    "        \n",
    "    #Calculates and returns gain ratio\n",
    "    g_ratio = feature_gain/IV\n",
    "    \n",
    "    return g_ratio\n",
    "\n",
    "def GenerateClassificationTree(dataset, target):\n",
    "    '''\n",
    "    Builds the decision tree\n",
    "    \n",
    "    @param dataset: classification set \n",
    "    @param target: class label\n",
    "    '''\n",
    "    #Creates the list of features and removes the class label from it\n",
    "    features = list(dataset.columns.values)\n",
    "    features.remove(target)\n",
    "    \n",
    "    \n",
    "    #Checks to make sure there are still features and classes to evaluate, and if not, returns the plurality of the target\n",
    "    if len(dataset[target].unique()) == 1 or len(features) == 0:\n",
    "        return dataset[target].mode()[0]\n",
    "\n",
    "    # Gets feature with the highest information gain\n",
    "    gain_ratio = [CalculateFeatureGainRatio(dataset, feature, target) for feature in features]\n",
    "    best_feature = features[np.argmax(gain_ratio)]\n",
    "\n",
    "    #Creates a tree dictionary that stores the subtree of the best feature\n",
    "    tree = {best_feature: {}}\n",
    "\n",
    "    # The chosen feature is removed from the features list\n",
    "    features = [feature for feature in features if feature != best_feature]\n",
    "\n",
    "    #Iterates through each value of the feature\n",
    "    for value in dataset[best_feature].unique():\n",
    "        \n",
    "        #Creates a subtree by recursively calling the decision tree function and adds it to the main tree\n",
    "        sub_df = dataset[dataset[best_feature] == value]\n",
    "        subtree = GenerateClassificationTree(sub_df, target)\n",
    "        tree[best_feature][value] = subtree\n",
    "\n",
    "    #The final decision tree is returned\n",
    "    return tree\n",
    "\n",
    "def GetClassPredictions(final_tree, test_data):\n",
    "    '''\n",
    "    Makes test predictions using the constructed decision tree\n",
    "    \n",
    "    @param final_tree: the decision tree\n",
    "    @param test_data: the test input\n",
    "    '''\n",
    "    \n",
    "    predicted_values = []\n",
    "    \n",
    "    #Iterates through each test input and gets the predicted values\n",
    "    for i, test_row in test_data.iterrows():\n",
    "        predicted_values.append(PredictClass(final_tree, test_row))\n",
    "    \n",
    "    #Returns the final list of predicted values\n",
    "    return predicted_values\n",
    "\n",
    "\n",
    "def PredictClass(tree, test_row):\n",
    "    '''\n",
    "    Makes test predictions using the constructed decision tree and an individual test input row\n",
    "    \n",
    "    @param final_tree: the decision tree\n",
    "    @param test_data: the test input\n",
    "    '''\n",
    "    #Gets the node by getting the first key of tree\n",
    "    node = list(tree.keys())[0]\n",
    "    #Randomly selects one of the feature values if the current one is not in the tree\n",
    "    if test_row[node] not in tree:\n",
    "            curr_keys = list((tree[node]).keys())\n",
    "            test_row[node] = choice(curr_keys)\n",
    "    #Creates a branch of a tree using the node and test row values\n",
    "    branch = tree[node][test_row[node]]\n",
    "    \n",
    "    #Checks if the branch is a string or integer, and returns the prediction if it is\n",
    "    if isinstance(branch, str) or isinstance(branch, np.int64):\n",
    "        return branch\n",
    "    #If it is not a leaf, calls itself recursively until leaf is found\n",
    "    else:\n",
    "        return PredictClass(branch, test_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eddf585",
   "metadata": {},
   "source": [
    "# Regression Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af1b5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(target):\n",
    "    '''\n",
    "    Calculates the mean squared error of a target vector\n",
    "    \n",
    "    @param target: target vector\n",
    "    \n",
    "    '''\n",
    "    mse = np.mean((target - np.mean(target)) ** 2)\n",
    "    if np.isnan(mse):\n",
    "        mse = 0\n",
    "    return mse\n",
    "\n",
    "def SplitData(data, target, feature, split_value):\n",
    "    '''\n",
    "    Splits numerical data into two and returns the mean squared error for each subset\n",
    "    \n",
    "    @param data: regression set \n",
    "    @param feature: the feature\n",
    "    @param target: class label\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    left_indices= data[feature] < split_value\n",
    "    right_indices = data[feature] >= split_value\n",
    "    left_subset = target[left_indices]\n",
    "    right_subset = target[right_indices]\n",
    "    left_mse = MSE(left_subset)\n",
    "    right_mse = MSE(right_subset)\n",
    "    return left_mse, right_mse\n",
    "    \n",
    "def SplitNominalData(data,class_label,feature):\n",
    "    '''\n",
    "    Splits categorical data and returns the mean squared error for each value\n",
    "    \n",
    "    @param data: regression set \n",
    "    @param feature: the feature\n",
    "    @param target: class label\n",
    "    \n",
    "    '''\n",
    "    mse_dict = {}\n",
    "    for split_value in np.unique(data[feature]):\n",
    "        target_values = data.loc[data[feature] == split_value,class_label]\n",
    "        curr_mse = MSE(target_values)\n",
    "        mse_dict[split_value]=curr_mse\n",
    "    return mse_dict\n",
    "\n",
    "def GenerateRegressionTree(data, class_label, depth=0, max_depth=3,nominal_features=[]):\n",
    "    '''\n",
    "    Builds the decision tree\n",
    "    \n",
    "    @param dataset: regresion set \n",
    "    @param target: class label\n",
    "    @param depth: current recursive depth\n",
    "    @param max_depth: maximum number of recursions\n",
    "    @param nominal_features: list of nominal features, if any\n",
    "    \n",
    "    '''\n",
    "    #Creates the list of features and removes the class label from it\n",
    "    features = list(data.columns.values)\n",
    "    features.remove(class_label)\n",
    "    target = data[class_label]\n",
    "    \n",
    "    #Checks to make sure there are still features to evaluate and max depth hasn't been reached, and if not, returns the average of the target\n",
    "    if MSE(target) == 0 or depth >= max_depth or len(features) == 0:\n",
    "        return np.mean(target)\n",
    "\n",
    "    #Gets the best feature by iterating through each feature, calculating the MSE, and choosing the one with the lowest MSE\n",
    "    best_feature = None\n",
    "    best_split_value = None\n",
    "    best_mse = np.inf\n",
    "    for feature in features:\n",
    "        if feature not in nominal_features or len(nominal_features)==0:\n",
    "            for split_value in np.unique(data[feature]):\n",
    "                left_mse, right_mse = SplitData(data, target, feature, split_value)\n",
    "                total_mse = left_mse + right_mse\n",
    "                if total_mse < best_mse:\n",
    "                    best_feature = feature\n",
    "                    best_split_value = split_value\n",
    "                    best_mse = total_mse\n",
    "        elif feature in nominal_features:\n",
    "            mse_dict = SplitNominalData(data,class_label,feature)\n",
    "            total_mse = sum(mse_dict.values())\n",
    "            if total_mse < best_mse:\n",
    "                best_feature=feature\n",
    "                best_mse=total_mse\n",
    "                \n",
    "    #Creates a tree dictionary that stores the subtree of the best feature\n",
    "    tree = {best_feature: {}}\n",
    "\n",
    "    #Creates subtree based on best split value from the lowest MSE and recursively calls generate tree function for numerical features\n",
    "    if best_feature not in nominal_features or len(nominal_features)==0:\n",
    "        l_data = data.loc[data[best_feature] < best_split_value]\n",
    "        left_data = l_data.drop(columns=[best_feature])\n",
    "        \n",
    "        r_data = data.loc[data[best_feature] >= best_split_value]\n",
    "        right_data = r_data.drop(columns=[best_feature])\n",
    "        \n",
    "        \n",
    "        tree[best_feature]['<{}'.format(best_split_value)] = GenerateRegressionTree(left_data,class_label, depth=depth+1, max_depth=max_depth,nominal_features=nominal_features)\n",
    "        tree[best_feature]['>{}'.format(best_split_value)] = GenerateRegressionTree(right_data,class_label, depth=depth+1, max_depth=max_depth,nominal_features=nominal_features)\n",
    "    \n",
    "    #Creates subtree by getting unique nominal feature values and recursively calls generate tree function \n",
    "    elif best_feature in nominal_features:\n",
    "        for split_value in np.unique(data[best_feature]):\n",
    "            indices = data.index[data[best_feature]==split_value].tolist()\n",
    "            curr_data = data.loc[indices]\n",
    "            curr_data.drop(columns=[best_feature])   \n",
    "            tree[best_feature][split_value] = GenerateRegressionTree(curr_data, class_label, depth=depth+1, max_depth=max_depth,nominal_features=nominal_features)   \n",
    "\n",
    "    #The final decision tree is returned\n",
    "    return tree\n",
    "\n",
    "\n",
    "\n",
    "def GetRegressionPredictions(final_tree, test_data, nominal_features):\n",
    "    '''\n",
    "    Makes test predictions using the constructed decision tree\n",
    "    \n",
    "    @param final_tree: the decision tree\n",
    "    @param test_data: the test input\n",
    "    @param nominal_features: list of nominal features, if any\n",
    "    '''\n",
    "    \n",
    "    predicted_values = []\n",
    "    \n",
    "     #Iterates through each test input and gets the predicted values\n",
    "    for i, test_row in test_data.iterrows():\n",
    "        predicted_values.append(PredictRegressionValue(final_tree, test_row, nominal_features))\n",
    "        \n",
    "    #Replaces nan values in predictions with 0\n",
    "    predicted_values = [0 if np.isnan(prediction) else prediction for prediction in predicted_values]\n",
    "    \n",
    "    #Returns the final list of predicted values\n",
    "    return predicted_values\n",
    "\n",
    "\n",
    "def PredictRegressionValue(tree, test_row, nominal_features):\n",
    "    '''\n",
    "    Makes test predictions using the constructed decision tree and an individual test input row\n",
    "    \n",
    "    @param tree: the decision tree\n",
    "    @param test_row: the test input\n",
    "    @param nominal_features: list of nominal features, if any\n",
    "    \n",
    "    '''\n",
    "    #Gets the node by getting the first key of tree\n",
    "    node = list(tree.keys())[0]\n",
    "    if node not in nominal_features:\n",
    "        for key in tree[node]:\n",
    "            compare = key[0]\n",
    "            compare_value = float(key.split(compare)[1])\n",
    "            \n",
    "            #Checks if the node is a greater than or less than range \n",
    "            #and checks the current node value\n",
    "            if compare == '>':\n",
    "                if test_row[node] >= compare_value:\n",
    "                    branch = tree[node][key]\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            if compare == '<':\n",
    "                if test_row[node] < compare_value:\n",
    "                    branch = tree[node][key]\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "    elif node in nominal_features:\n",
    "        #Randomly selects one of the feature values if the current one is not in the tree\n",
    "        if test_row[node] not in tree:\n",
    "            curr_keys = list((tree[node]).keys())\n",
    "            test_row[node] = choice(curr_keys)\n",
    "        branch = tree[node][test_row[node]]\n",
    "        \n",
    "    #Checks if the branch is a string or integer or float, and returns the prediction if it is\n",
    "    if isinstance(branch, str) or isinstance(branch, np.int64) or isinstance(branch,float):\n",
    "        return branch\n",
    "    \n",
    "    #If it is not a leaf, calls itself recursively until leaf is found\n",
    "    else:\n",
    "        return PredictRegressionValue(branch, test_row, nominal_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d96da10",
   "metadata": {},
   "source": [
    "# Reduced Error Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "deef4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_error_pruning(tree, dataset, class_label):\n",
    "    '''\n",
    "    Performs reduced error pruning on decision tree\n",
    "    \n",
    "    @param tree: built decision tree\n",
    "    @param dataset: test data\n",
    "    @param class_label: class label\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Checks if the tree is a leaf and returns the tree if it is\n",
    "    if len(tree) <= 1:\n",
    "        return tree\n",
    "    \n",
    "    #Gets the node from the first key of the tree and all the subtrees of the tree\n",
    "    node = list(tree.keys())[0]\n",
    "    subtrees = tree[node]\n",
    "    \n",
    "    #Checks for leaf nodes\n",
    "    if all(isinstance(subtrees[k], str) for k in subtrees):\n",
    "        return tree\n",
    "    \n",
    "    #Recursively prunes each subtree\n",
    "    for k in subtrees:\n",
    "        if isinstance(subtrees[k], dict):\n",
    "            subtree = {k: subtrees[k]}\n",
    "            subtree_pruned = reduced_error_pruning(subtree, dataset, class_label)\n",
    "            if len(subtree_pruned) == 1:\n",
    "                #Prunes subtree if it has been reduced to a single leaf node\n",
    "                tree[node][k] = subtree_pruned[k]\n",
    "            else:\n",
    "                # Checks accuracy of subtree and if greater than the previous accuracy, it is added onto the tree\n",
    "                subtree_accuracy = get_accuracy(subtree_pruned, dataset, class_label)\n",
    "                original_accuracy = get_accuracy(subtree, dataset, class_label)\n",
    "                if subtree_accuracy >= original_accuracy:\n",
    "                    tree[node][k] = subtree_pruned[k]\n",
    "    \n",
    "    # Return the pruned tree\n",
    "    return tree\n",
    "\n",
    "\n",
    "def get_accuracy(tree, test_data, class_label):\n",
    "    '''\n",
    "    Checks accuracy of pruning subtrees\n",
    "    \n",
    "    @param tree: pruning subtree\n",
    "    @param test_data: test data\n",
    "    @param class_label: class label\n",
    "    \n",
    "    '''\n",
    "    num_correct = 0\n",
    "    num_total = len(test_data)\n",
    "    for value in test_data:\n",
    "        prediction = predict(tree, instance)\n",
    "        if prediction == value[class_label]:\n",
    "            num_correct += 1\n",
    "    accuracy = num_correct / num_total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe77c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThresholds(target):  \n",
    "    '''\n",
    "    Gets error threshold values for tuning\n",
    "    \n",
    "    @param target: target vector\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Gets the range of the target and gets the threholds for the 90%, 95%, and 99% confidence intervals\n",
    "    arr_range = np.max(target) - np.min(target)\n",
    "    accuracies = [0.9,0.95,0.99]\n",
    "    thresholds = []\n",
    "    \n",
    "    #Adds each threshold value to list and returns\n",
    "    for value in accuracies:\n",
    "        thresholds.append((1-value)*arr_range)\n",
    "        \n",
    "    return thresholds\n",
    "            \n",
    "def tuneError(full_data,tuning_dataset,class_label,nominal_features=[]):\n",
    "    '''\n",
    "    Tunes the error\n",
    "    \n",
    "    @param full_data: the full dataset\n",
    "    @param tuning_dataset: the 20% of dataset for tuning\n",
    "    @param class_label: class label\n",
    "    @param nominal_features: list of nominal features, if any\n",
    "    \n",
    "    '''\n",
    "    thresholds = getThresholds(full_data[class_label].to_numpy()) \n",
    "\n",
    "    errors_dict = {}       \n",
    "    for threshold in thresholds:\n",
    "        print('Current Error Being Tested')\n",
    "        acc = RunExperiment(tuning_dataset, task_type='Regression', k = 5, class_label = class_label, tuning=True, error=threshold,nominal_features=nominal_features)\n",
    "        errors_dict[threshold]=acc\n",
    "    return max(errors_dict, key=errors_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76395692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeparateData(dataset):\n",
    "    '''\n",
    "    Separates tuning and experiment data\n",
    "    \n",
    "    @param full_data: the full dataset\n",
    "    \n",
    "    '''\n",
    "    #Separates 20% of data for tuning and leaves rest for training/testing\n",
    "    tuning_data = dataset.sample(frac=.2)\n",
    "    non_tuning_data = dataset.drop(tuning_data.index)\n",
    "    \n",
    "    return (tuning_data,non_tuning_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e19465",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9048fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(task_type, true_values, predicted_values,error=None):\n",
    "    '''\n",
    "    Evaluates the data based on task type\n",
    "    \n",
    "    @param task_type: specifies whether the task is 'Classification' or 'Regression'\n",
    "    @param true_values: actual values of the data\n",
    "    @param predicted_values: values predicted by the model\n",
    "    \n",
    "    '''\n",
    "    if task_type == 'Regression':\n",
    "        num_correct_values = 0\n",
    "        for index in range(len(true_values)):\n",
    "            min_threshold = float(true_values[index]-error)\n",
    "            max_threshold = float(true_values[index]+error)\n",
    "\n",
    "            if (predicted_values[index] >= min_threshold) and (predicted_values[index] <= max_threshold):\n",
    "                num_correct_values = num_correct_values + 1\n",
    "\n",
    "        regression_accuracy = num_correct_values/len(true_values)\n",
    "        mean_squared_error = np.square(np.subtract(true_values,predicted_values)).mean()\n",
    "        return regression_accuracy,mean_squared_error\n",
    "    \n",
    "    #Calculates classification accuracy and error rate for classification data\n",
    "    elif task_type == 'Classification':\n",
    "        num_correct_values = 0\n",
    "        for index in range(len(true_values)):\n",
    "            if true_values[index]==predicted_values[index]:\n",
    "                num_correct_values = num_correct_values + 1\n",
    "        classification_accuracy = num_correct_values/len(true_values)\n",
    "        error_rate = 1-classification_accuracy\n",
    "        return classification_accuracy, error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a0338f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunExperiment(dataset, task_type, k = 5, class_label = None, tuning=False, error=None,nominal_features=[],pruning=False):\n",
    "    '''\n",
    "    Runs the experiments using the processed data, performs cross validation to get testing and training data,\n",
    "    standardizes the data, feeds into the algorithm, and uses the output to evaluate the accuracy\n",
    "    \n",
    "    @param dataset: pre-processed dataframe\n",
    "    @param validation_type: specifies whether the task is 'k-fold' or 'kx2 '\n",
    "    @param task_type: specifies whether the task is 'Classification' or 'Regression'\n",
    "    @param num_folds: number of folds--only needed when validation type is k-fold\n",
    "    @param k: k value to be used for cross validation-only needed when validation type is kx2\n",
    "    @param class_label: name of class column\n",
    "    \n",
    "    '''\n",
    "    classification = False\n",
    "    if task_type == 'classification' or task_type == 'Classification':\n",
    "        classification = True\n",
    "        \n",
    "    avg_accuracy = 0\n",
    "    avg_error = 0\n",
    "    avg_MSE = 0\n",
    "\n",
    "    #Performs k x 2 cross validation with parameter data\n",
    "    validation_output = k_x_2_cross_validation(dataset, k, classification, class_label,tuning=False)\n",
    "    for k in validation_output:\n",
    "        print('K = ' + str(k))\n",
    "        for num in validation_output[k]:\n",
    "            print('  Experiment ' + str(num))\n",
    "\n",
    "            #Gets test and training data for each k\n",
    "            test_data = validation_output[k][num]['test']\n",
    "            train_data = validation_output[k][num]['train']\n",
    "\n",
    "            print('   Test Fold Size: ' + str(len(test_data)))\n",
    "            print('   Train Fold Size: ' + str(len(train_data)))\n",
    "\n",
    "            #Gets the prediction value from the null model\n",
    "            #predicted_values = KNN1(train_data,test_data,3,class_label,task_type)\n",
    "            #predicted_values = KNN(train_data,test_data,3,class_label,task_type)\n",
    "            true_values = test_data[class_label].to_list()\n",
    "            \n",
    "            if task_type == 'Classification':\n",
    "                tree=GenerateClassificationTree(train_data,class_label)\n",
    "                \n",
    "                if pruning:\n",
    "                    pruned_tree = reduced_error_pruning(tree,train_data,class_label)\n",
    "                    tree=pruned_tree\n",
    "\n",
    "                predicted_values = []\n",
    "                test_input =  test_data.drop(columns=class_label)\n",
    "                predicted_values = GetClassPredictions(tree,test_input)\n",
    "                \n",
    "            if task_type == 'Regression':\n",
    "                tree = GenerateRegressionTree(train_data,class_label,max_depth=10,nominal_features=nominal_features)\n",
    "                if pruning:\n",
    "                    pruned_tree = reduced_error_pruning(tree,train_data,class_label)\n",
    "                    tree=pruned_tree\n",
    "                \n",
    "                test_input =  test_data.drop(columns=class_label)\n",
    "                predicted_values = GetRegressionPredictions(tree,test_input,nominal_features=nominal_features)\n",
    "                \n",
    "\n",
    "\n",
    "            #Gets corresponding evaluation metric depending on task type and prints to console\n",
    "            if task_type == 'Classification':\n",
    "                evaluation = Evaluate(task_type,true_values,predicted_values)\n",
    "                class_accuracy = evaluation[0]\n",
    "                error = evaluation[1]\n",
    "                avg_accuracy = avg_accuracy + class_accuracy\n",
    "                avg_error = avg_error + error\n",
    "                print('    Classification Accuracy: '+ str(class_accuracy))\n",
    "                print('    Error: ' + str(error))\n",
    "            elif task_type == 'Regression':\n",
    "                evaluation = Evaluate(task_type,true_values,predicted_values,error=error)\n",
    "                reg_accuracy = evaluation[0]\n",
    "                MSE = evaluation[1]\n",
    "                avg_accuracy = avg_accuracy + reg_accuracy\n",
    "                avg_MSE = avg_MSE + MSE\n",
    "                print('    Regression Accuracy: '+ str(reg_accuracy))\n",
    "                print('    Mean Squared Error: ' + str(MSE))\n",
    "            print('')\n",
    "\n",
    "    #Gets the average of the evaluation metric over all folds and prints it\n",
    "    if task_type == 'Classification':\n",
    "            print('Average Classification Accuracy: '+ str(avg_accuracy/(2*k)))\n",
    "            print('Average Error: ' + str(avg_error/(2*k)))\n",
    "            if tuning == True:\n",
    "                return avg_error/(2*k)\n",
    "    elif task_type == 'Regression':\n",
    "        print('Average Regression Accuracy: '+ str(avg_accuracy/(2*k)))\n",
    "        print('Average Mean Squared Error: ' + str(avg_MSE/(2*k)))\n",
    "        if tuning == True:\n",
    "            return avg_accuracy/(2*k)\n",
    "\n",
    "    print('')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
